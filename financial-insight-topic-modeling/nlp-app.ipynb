{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "\n",
    "from transformers import pipeline\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_df = pd.read_csv('cp_articles 2.csv')\n",
    "cp_df = cp_df.dropna(subset='content')\n",
    "cp_df = cp_df.drop_duplicates(subset='content')\n",
    "cp_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    A function to preprocess text by performing the following steps:\n",
    "    1. Convert to lowercase\n",
    "    2. Remove punctuation and whitespace\n",
    "    3. Remove stopwords\n",
    "    4. Lemmatize words\n",
    "    \"\"\"\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation and whitespace\n",
    "    doc = nlp(text)\n",
    "    tokens = [token for token in doc if not token.is_punct and not token.is_space]\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if not token.is_stop and str(token) not in ['company', 'year', 'market']]\n",
    "\n",
    "    # Lemmatize words\n",
    "    tokens = [token.lemma_ for token in tokens]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(series, return_df=False, return_obj=False):\n",
    "\n",
    "    umap_obj = UMAP()\n",
    "    bert_model = BERTopic(umap_model=umap_obj)\n",
    "    topics, probability =  bert_model.fit_transform(series)\n",
    "    docTopics_df = bert_model.get_document_info(series)\n",
    "    if return_df:\n",
    "        return docTopics_df\n",
    "    if return_obj:\n",
    "        return bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = cp_df[['content']]\n",
    "content = content.reset_index()\n",
    "content['preproces_content'] = content['content'].apply(preprocess_text)\n",
    "content['preproces_content'] = content['preproces_content'].astype('str')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.to_csv('content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_model = bert_model(content['preproces_content'], return_obj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = bert_model(content['preproces_content'], return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1_company_us_investment_investor',\n",
       "       '0_company_dividend_index_growth', '6_bond_fund_portfolio_high',\n",
       "       '3_china_company_trade_global', '4_economy_us_market_volatility',\n",
       "       '1_plan_retirement_participant_sponsor',\n",
       "       '2_rate_inflation_fed_bond', '7_bond_tax_municipal_muni',\n",
       "       '5_election_house_senate_president'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
